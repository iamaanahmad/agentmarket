"""
High-performance exploit pattern database
Optimized for <100ms pattern matching
"""

import asyncio
import json
import time
from typing import List, Dict, Any, Set
from dataclasses import dataclass

from typing import Optional
import redis.asyncio as redis
from loguru import logger

try:
    from ..core.config import get_settings
    from ..models.schemas import ExploitPattern
except ImportError:
    # Fallback for direct execution
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    from core.config import get_settings
    from models.schemas import ExploitPattern


@dataclass
class PatternMatch:
    """Pattern match result"""
    pattern_id: str
    severity: str
    confidence: float
    description: str
    evidence: Dict[str, Any]


class ExploitDatabase:
    """High-performance exploit pattern database with in-memory caching"""
    
    def __init__(self):
        self.settings = get_settings()
        self.redis_client: Optional[redis.Redis] = None
        
        # In-memory pattern cache for ultra-fast lookups
        self.program_patterns: Dict[str, List[ExploitPattern]] = {}
        self.instruction_patterns: List[ExploitPattern] = []
        self.critical_patterns: Set[str] = set()
        
        # Performance metrics
        self.cache_hits = 0
        self.cache_misses = 0
        
    async def initialize(self):
        """Initialize database connection and load patterns into memory"""
        try:
            # Connect to Redis
            self.redis_client = redis.from_url(
                self.settings.redis_url,
                decode_responses=True,
                socket_connect_timeout=1,
                socket_timeout=1
            )
            await self.redis_client.ping()
            logger.info("✅ Redis connected for exploit database")
            
            # Load patterns into memory for fast access
            await self._load_patterns_to_memory()
            
        except Exception as e:
            logger.warning(f"⚠️ Redis connection failed: {e}")
            self.redis_client = None
            # Load basic patterns even without Redis
            await self._load_basic_patterns()
    
    async def check_patterns(self, parsed_tx: Dict[str, Any]) -> List[PatternMatch]:
        """
        Legacy pattern checking method - delegates to new pattern matcher
        Maintained for backward compatibility
        """
        logger.warning("⚠️ Using legacy check_patterns method. Consider upgrading to PatternMatcher service.")
        
        start_time = time.time()
        
        # Simple fallback pattern matching
        matches = []
        
        # Check critical patterns only for performance
        programs = parsed_tx.get("programs", [])
        for program_id in programs:
            if program_id in self.program_patterns:
                for pattern in self.program_patterns[program_id]:
                    if pattern.severity == "CRITICAL":
                        matches.append(PatternMatch(
                            pattern_id=pattern.pattern_id,
                            severity=pattern.severity,
                            confidence=0.99,
                            description=pattern.description,
                            evidence={"program_id": program_id, "type": "critical_program"}
                        ))
        
        match_time = (time.time() - start_time) * 1000
        logger.debug(f"⚡ Legacy pattern matching completed in {match_time:.1f}ms ({len(matches)} matches)")
        
        return matches
    
    async def _load_patterns_to_memory(self):
        """Load exploit patterns into memory for fast access"""
        try:
            # Load from Redis or database
            patterns = await self._fetch_patterns_from_storage()
            
            # Organize patterns by type for fast lookup
            for pattern in patterns:
                # Program-based patterns
                for program_id in pattern.program_ids:
                    if program_id not in self.program_patterns:
                        self.program_patterns[program_id] = []
                    self.program_patterns[program_id].append(pattern)
                
                # Instruction patterns
                if pattern.instruction_patterns:
                    self.instruction_patterns.append(pattern)
                
                # Critical patterns
                if pattern.severity == "CRITICAL":
                    self.critical_patterns.add(pattern.pattern_id)
            
            logger.info(f"✅ Loaded {len(patterns)} exploit patterns to memory")
            
        except Exception as e:
            logger.error(f"❌ Failed to load patterns: {e}")
            await self._load_basic_patterns()
    
    async def _load_basic_patterns(self):
        """Load basic hardcoded patterns as fallback"""
        basic_patterns = [
            ExploitPattern(
                pattern_id="wallet_drainer_v1",
                name="Wallet Drainer Pattern",
                description="Known wallet drainer contract",
                severity="CRITICAL",
                program_ids=["DrainWa11etProgramId123456789"],
                instruction_patterns=["drain_all"],
                account_patterns=[]
            ),
            ExploitPattern(
                pattern_id="unlimited_approval",
                name="Unlimited Token Approval",
                description="Unlimited token spending approval",
                severity="HIGH",
                program_ids=[],
                instruction_patterns=["approve_max"],
                account_patterns=[]
            ),
            ExploitPattern(
                pattern_id="authority_theft",
                name="Authority Theft Pattern",
                description="Unauthorized authority delegation",
                severity="HIGH",
                program_ids=[],
                instruction_patterns=["set_authority"],
                account_patterns=[]
            )
        ]
        
        for pattern in basic_patterns:
            for program_id in pattern.program_ids:
                if program_id not in self.program_patterns:
                    self.program_patterns[program_id] = []
                self.program_patterns[program_id].append(pattern)
            
            if pattern.instruction_patterns:
                self.instruction_patterns.append(pattern)
            
            if pattern.severity == "CRITICAL":
                self.critical_patterns.add(pattern.pattern_id)
        
        logger.info(f"✅ Loaded {len(basic_patterns)} basic patterns")
    
    async def _check_critical_patterns(self, parsed_tx: Dict[str, Any]) -> List[PatternMatch]:
        """Check for critical exploit patterns (immediate danger)"""
        matches = []
        
        programs = parsed_tx.get("programs", [])
        
        for program_id in programs:
            if program_id in self.program_patterns:
                for pattern in self.program_patterns[program_id]:
                    if pattern.severity == "CRITICAL":
                        matches.append(PatternMatch(
                            pattern_id=pattern.pattern_id,
                            severity=pattern.severity,
                            confidence=0.99,
                            description=pattern.description,
                            evidence={"program_id": program_id, "type": "critical_program"}
                        ))
        
        return matches
    
    async def _check_program_patterns(self, parsed_tx: Dict[str, Any]) -> List[PatternMatch]:
        """Check program-based exploit patterns"""
        matches = []
        
        programs = parsed_tx.get("programs", [])
        
        for program_id in programs:
            if program_id in self.program_patterns:
                for pattern in self.program_patterns[program_id]:
                    if pattern.severity != "CRITICAL":  # Already checked
                        confidence = 0.9 if pattern.severity == "HIGH" else 0.7
                        matches.append(PatternMatch(
                            pattern_id=pattern.pattern_id,
                            severity=pattern.severity,
                            confidence=confidence,
                            description=pattern.description,
                            evidence={"program_id": program_id, "type": "program_match"}
                        ))
        
        return matches
    
    async def _check_instruction_patterns(self, parsed_tx: Dict[str, Any]) -> List[PatternMatch]:
        """Check instruction-based exploit patterns"""
        matches = []
        
        instructions = parsed_tx.get("instructions", [])
        
        for pattern in self.instruction_patterns:
            for instruction_pattern in pattern.instruction_patterns:
                for instruction in instructions:
                    if self._matches_instruction_pattern(instruction, instruction_pattern):
                        confidence = 0.8 if pattern.severity == "HIGH" else 0.6
                        matches.append(PatternMatch(
                            pattern_id=pattern.pattern_id,
                            severity=pattern.severity,
                            confidence=confidence,
                            description=pattern.description,
                            evidence={
                                "instruction_index": instruction["index"],
                                "pattern": instruction_pattern,
                                "type": "instruction_match"
                            }
                        ))
        
        return matches
    
    async def _check_behavioral_patterns(self, parsed_tx: Dict[str, Any]) -> List[PatternMatch]:
        """Check behavioral exploit patterns"""
        matches = []
        
        # Check for suspicious behavioral patterns
        instructions = parsed_tx.get("instructions", [])
        accounts = parsed_tx.get("accounts", [])
        
        # Pattern: Multiple token transfers to new accounts
        if len(instructions) > 5 and len(accounts) > 10:
            matches.append(PatternMatch(
                pattern_id="mass_transfer_pattern",
                severity="MEDIUM",
                confidence=0.6,
                description="Multiple token transfers to many accounts",
                evidence={
                    "instruction_count": len(instructions),
                    "account_count": len(accounts),
                    "type": "behavioral_pattern"
                }
            ))
        
        # Pattern: Complex instruction sequence
        if len(instructions) > 20:
            matches.append(PatternMatch(
                pattern_id="complex_transaction",
                severity="LOW",
                confidence=0.5,
                description="Unusually complex transaction with many instructions",
                evidence={
                    "instruction_count": len(instructions),
                    "type": "complexity_pattern"
                }
            ))
        
        return matches
    
    def _matches_instruction_pattern(self, instruction: Dict[str, Any], pattern: str) -> bool:
        """Check if instruction matches a pattern"""
        # Simplified pattern matching - would be more sophisticated in production
        instruction_data = instruction.get("data", "").lower()
        
        if pattern == "approve_max":
            return "ffffff" in instruction_data and len(instruction_data) > 16
        elif pattern == "set_authority":
            return "authority" in instruction_data or len(instruction_data) == 64
        elif pattern == "drain_all":
            return "transfer" in instruction_data and len(instruction_data) > 32
        
        return False
    
    def _generate_cache_key(self, parsed_tx: Dict[str, Any]) -> str:
        """Generate cache key for transaction"""
        # Create hash from programs and instruction data
        programs = tuple(sorted(parsed_tx.get("programs", [])))
        instruction_data = tuple(
            instr.get("data", "")[:16] for instr in parsed_tx.get("instructions", [])
        )
        return str(hash((programs, instruction_data)))
    
    async def _cache_pattern_results(self, cache_key: str, matches: List[PatternMatch]):
        """Cache pattern matching results"""
        if self.redis_client:
            try:
                serialized_matches = [
                    {
                        "pattern_id": match.pattern_id,
                        "severity": match.severity,
                        "confidence": match.confidence,
                        "description": match.description,
                        "evidence": match.evidence
                    }
                    for match in matches
                ]
                
                await self.redis_client.setex(
                    f"patterns:{cache_key}",
                    self.settings.cache_ttl,
                    json.dumps(serialized_matches)
                )
            except Exception as e:
                logger.warning(f"Failed to cache pattern results: {e}")
    
    async def _fetch_patterns_from_storage(self) -> List[ExploitPattern]:
        """Fetch patterns from persistent storage"""
        # In production, this would query the database
        # For now, return the basic patterns
        return []
    
    def is_ready(self) -> bool:
        """Check if exploit database is ready"""
        return len(self.program_patterns) > 0 or len(self.instruction_patterns) > 0
    
    async def close(self):
        """Close database connections"""
        if self.redis_client:
            await self.redis_client.close()
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """Get performance statistics"""
        total_requests = self.cache_hits + self.cache_misses
        cache_hit_rate = self.cache_hits / total_requests if total_requests > 0 else 0
        
        return {
            "cache_hits": self.cache_hits,
            "cache_misses": self.cache_misses,
            "cache_hit_rate": cache_hit_rate,
            "patterns_loaded": len(self.program_patterns) + len(self.instruction_patterns),
            "critical_patterns": len(self.critical_patterns)
        }